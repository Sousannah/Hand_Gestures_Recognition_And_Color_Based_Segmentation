{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "offset = 20\n",
    "imgSize = 300\n",
    "\n",
    "correct = 0\n",
    "Accuracy = 0\n",
    "counter = 0\n",
    "\n",
    "labels = [\"Down\", \"Up\", \"Right\", \"Back\", \"Front\", \"Left\"]\n",
    "\n",
    "# Load the hand gesture classifier\n",
    "classifier = Classifier('hand_gesture_model01.h5', \"Labels.txt\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgOutput = img.copy()\n",
    "    \n",
    "    # Convert the image to the HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds of the blue color in HSV\n",
    "    lower_blue = np.array([101,50,38])\n",
    "    upper_blue = np.array([110, 255, 255])\n",
    "\n",
    "    # Create a mask to detect the blue color\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) > 0:\n",
    "        # Sort the contours by area and find the largest one\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        largest_contour = contours[0]\n",
    "\n",
    "        # Get the bounding box of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        # Check if the cropped image is valid (non-empty)\n",
    "        if imgCrop.size != 0:\n",
    "            imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "            imgCropShape = imgCrop.shape\n",
    "\n",
    "            aspectRatio = h / w\n",
    "\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "                \n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "                \n",
    "          \n",
    "            # Create a mask for the blue color region\n",
    "            blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "            # Find contours in the blue color mask\n",
    "            blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Create a black background\n",
    "            blue_segmented = np.zeros_like(img)\n",
    "\n",
    "            if len(blue_contours) > 0:\n",
    "                # Sort the contours by area and find the largest one\n",
    "                blue_contours = sorted(blue_contours, key=cv2.contourArea, reverse=True)\n",
    "                largest_blue_contour = blue_contours[0]\n",
    "\n",
    "                # Draw the largest blue contour on the segmented image\n",
    "                cv2.drawContours(blue_segmented, [largest_blue_contour], -1, (0, 0, 255), -1)\n",
    "\n",
    "            # Create a white mask of the same size as the segmented image\n",
    "            white_mask = np.ones_like(blue_segmented) * 255\n",
    "\n",
    "            \n",
    "            # Use bitwise AND to set white mask's pixels to white wherever segmented image has blue pixels\n",
    "            result = cv2.bitwise_and(white_mask, blue_segmented)\n",
    "\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "                result = cv2.resize(result, (wCal, imgSize))  # Resize result to match imgWhite shape\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "                result = cv2.resize(result, (imgSize, hCal))  # Resize result to match imgWhite shape\n",
    "                \n",
    "            cv2.imshow(\"Blue Segmentation\", result)\n",
    "            \n",
    "            modelImg = imgWhite.copy()\n",
    "            gray = cv2.cvtColor(modelImg, cv2.COLOR_BGR2GRAY)\n",
    "            gray_inverted = cv2.bitwise_not(gray)\n",
    "            contours, hierarchy = cv2.findContours(gray_inverted, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            _, binary = cv2.threshold(gray_inverted, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Convert binary image to 3-channel grayscale\n",
    "            binary_rgb = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            prediction, index = classifier.getPrediction(binary_rgb, draw=False)\n",
    "            print(prediction, index)\n",
    "            \n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset - 50),\n",
    "                          (x - offset + 90, y - offset - 50 + 50), (255, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(imgOutput, labels[index], (x, y - 26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset),\n",
    "                          (x + w + offset, y + h + offset), (255, 0, 255), 4)\n",
    "\n",
    "            print(Accuracy)\n",
    "            cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "            cv2.imshow(\"Segmentation\", binary)\n",
    "            cv2.imshow(\"ImageCrop\", imgCrop)\n",
    "            \n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # Exit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(Accuracy)\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
